import numpy as np
import pandas as pd



df=pd.read_csv('cars.csv')


df.head()


df['brand'].value_counts()


df['fuel'].value_counts()





pd.get_dummies(df,columns=['fuel','owner'])
#only used in data analytics not in machine learning projects





pd.get_dummies(df,columns=['fuel','owner'] ,drop_first=True)





from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(df.iloc[:,0:4],df.iloc[:,-1],test_size=0.2,random_state=0)


X_train.shape,X_test.shape


X_train.head()


from sklearn.preprocessing import OneHotEncoder


ohe=OneHotEncoder()


X_train_new=ohe.fit_transform(X_train[['fuel','owner']]).toarray()


X_test_new=ohe.transform(X_test[['fuel','owner']]).toarray()


X_train_new


np.hstack((X_train[['brand','km_driven']].values,X_train_new)).shape


ohe=OneHotEncoder(drop='first')
#it means remove 1st column concept of dummy values and multicollineraity


ohe=OneHotEncoder(drop='first',sparse=False , dtype=np.int32)
# aba to arrray garna parena hai kta kt ho 





counts=df['brand'].value_counts()


df['brand'].nunique()
threshold=100


replace=counts[counts <=threshold].index


pd.get_dummies(df['brand'].replace(replace,'uncommon')).sample(5)



